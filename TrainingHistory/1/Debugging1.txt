# 첫 번째 모델 파인튜닝 및 학습 결과

(ossProject_Model) PS C:\Users\Administrator\Desktop\Current_Semester\OpenSource_Programming\PROJECT\model> python .\klue_model_training.py
The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.
0it [00:00, ?it/s]
🎯 4단계: KLUE-BERT 키워드 추출 모델 학습
============================================================
라벨링된 데이터를 사용하여 단순 키워드 추출 모델 학습
라벨 체계: O (비키워드), B-KEY (키워드 시작), I-KEY (키워드 내부)
============================================================
📂 라벨링된 KLUE 데이터 로드 중...
✅ 발견된 라벨링 파일: 1개
📄 로딩 중: KLUE_tokenized_answers1_labeled.json
   ⚠️ 토큰-라벨 길이 불일치 샘플 건너뜀
   ✅ 9개 유효 샘플, 34개 키워드

📊 라벨링 데이터 로드 완료:
   총 샘플: 9개
   총 키워드: 34개
   평균 키워드/샘플: 3.8개

📈 라벨 분포:
   O: 185개 (83.0%)
   B-KEY: 34개 (15.2%)
   I-KEY: 4개 (1.8%)

💡 라벨링 예시:
   원본: 봄에는 가족과 항상 벚꽃 명소로 유명한 곳들을 하나씩 찾아갔던 기억이 나요. 가족과 벚꽃 ...
   🔑 봄 -> B-KEY
   🔑 가족 -> B-KEY
   🔑 벚꽃 -> B-KEY
C:\Users\Administrator\anaconda3\envs\ossProject_Model\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

🔧 KLUE-BERT 토크나이저 로드 완료

📊 데이터셋 분할 및 데이터 로더 생성...
✅ 데이터 분할 완료:
   훈련 데이터: 5개
   검증 데이터: 2개
   테스트 데이터: 2개
   배치 크기: 16

📈 훈련 데이터 라벨 분포:
   O: 100개 (84.0%)
   B-KEY: 19개 (16.0%)
C:\Users\Administrator\anaconda3\envs\ossProject_Model\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

🏗️ KLUE-BERT 키워드 추출 모델 생성 완료

🚀 KLUE-BERT 키워드 추출 모델 학습 시작!
   에포크: 5
   학습률: 2e-05
   사용 장치: cpu

📚 에포크 1/5
훈련 1: 100%|████████████████████████████████████| 1/1 [00:07<00:00,  7.30s/it, Loss=1.5097]
   훈련 손실: 1.5097
   훈련 F1: 0.1435
검증 평가: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.58it/s]
   검증 F1: 0.3542 (정밀도: 0.5139, 재현율: 0.2917)
   🏆 최고 성능 모델 저장 (F1: 0.3542)

📚 에포크 2/5
훈련 2: 100%|████████████████████████████████████| 1/1 [00:05<00:00,  5.19s/it, Loss=1.0599]
   훈련 손실: 1.0599
   훈련 F1: 0.4563
검증 평가: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.80it/s]
   검증 F1: 0.5609 (정밀도: 0.6252, 재현율: 0.5208)
   🏆 최고 성능 모델 저장 (F1: 0.5609)

📚 에포크 3/5
훈련 3: 100%|████████████████████████████████████| 1/1 [00:05<00:00,  5.23s/it, Loss=0.9187]
   훈련 손실: 0.9187
   훈련 F1: 0.6330
검증 평가: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.77it/s]
   검증 F1: 0.6365 (정밀도: 0.6558, 재현율: 0.6250)
   🏆 최고 성능 모델 저장 (F1: 0.6365)

📚 에포크 4/5
훈련 4: 100%|████████████████████████████████████| 1/1 [00:05<00:00,  5.13s/it, Loss=0.7449]
   훈련 손실: 0.7449
   훈련 F1: 0.6980
검증 평가: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.81it/s]
   검증 F1: 0.6284 (정밀도: 0.6338, 재현율: 0.6250)

📚 에포크 5/5
훈련 5: 100%|████████████████████████████████████| 1/1 [00:04<00:00,  4.94s/it, Loss=0.7068]
   훈련 손실: 0.7068
   훈련 F1: 0.6907
검증 평가: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.53it/s]
   검증 F1: 0.6512 (정밀도: 0.6620, 재현율: 0.6458)
   🏆 최고 성능 모델 저장 (F1: 0.6512)

🎉 학습 완료! 최고 검증 F1: 0.6512
테스트 평가: 100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  1.70it/s]

🔍 최종 테스트 평가 결과:
   정밀도: 0.7460
   재현율: 0.7500
   F1 스코어: 0.7479

📊 상세 분류 리포트:
              precision    recall  f1-score   support

           O       0.85      0.85      0.85        47
       B-KEY       0.22      0.25      0.24         8
       I-KEY       0.00      0.00      0.00         1

    accuracy                           0.75        56
   macro avg       0.36      0.37      0.36        56
weighted avg       0.75      0.75      0.75        56


💾 모델 저장 중: klue_keyword_extractor
❌ 모델 저장 실패: 'KLUEKeywordExtractor' object has no attribute 'save_pretrained'

🧪 추론 테스트
==================================================

테스트 1: 봄에는 가족과 벚꽃 구경을 갔어요
키워드 추출 결과:
  🔑 ##에 -> B-KEY
  🔑 ##는 -> B-KEY
  🔑 가족 -> B-KEY
🎯 추출된 키워드: ['에', '는', '가족']

테스트 2: 남편과 함께 병원에 갔습니다
키워드 추출 결과:
  🔑 남편 -> B-KEY
  🔑 ##과 -> B-KEY
  🔑 ##니다 -> B-KEY
🎯 추출된 키워드: ['남편', '과', '니다']

테스트 3: 어머니와 시장에서 과일을 샀어요
키워드 추출 결과:
  🔑 어머니 -> B-KEY
🎯 추출된 키워드: ['어머니']

테스트 4: 아들이 학교에서 친구들과 놀았어요
키워드 추출 결과:
  🔑 아들 -> B-KEY
  🔑 학교 -> B-KEY
  🔑 친구 -> B-KEY
  🔑 ##과 -> B-KEY
🎯 추출된 키워드: ['아들', '학교', '친구', '과']
📊 학습 히스토리 그래프 저장: training_history.png

🎉 4단계 완료 보고서
========================================
✅ 훈련 데이터: 9개
✅ 최고 검증 F1: 0.6512
✅ 최종 테스트 F1: 0.7479
✅ 모델 저장: klue_keyword_extractor/
✅ 라벨 체계: 3개 클래스 (O, B-KEY, I-KEY)
