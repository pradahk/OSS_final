🎯 개선된 4단계: KLUE-BERT 키워드 추출 모델 학습
============================================================
라벨링된 데이터를 사용하여 단순 키워드 추출 모델 학습
라벨 체계: O (비키워드), B-KEY (키워드 시작), I-KEY (키워드 내부)
============================================================
🧹 이전 학습 결과 정리 중...
   🗑️ 파일 삭제: best_model_20250618_164856.pt
   🗑️ 파일 삭제: training_history_20250618_164856.png
   🗑️ 폴더 삭제: klue_keyword_extractor_20250618_164856
✅ 3개 파일/폴더 정리 완료

🕐 학습 세션 ID: 20250618_173746
📂 라벨링된 KLUE 데이터 로드 중...
✅ 발견된 라벨링 파일: 32개
📄 로딩 중: KLUE_tokenized_answers10_labeled.json
   ✅ 9개 유효 샘플, 34개 키워드
📄 로딩 중: KLUE_tokenized_answers11_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers12_labeled.json
   ✅ 10개 유효 샘플, 36개 키워드
📄 로딩 중: KLUE_tokenized_answers13_labeled.json
   ✅ 10개 유효 샘플, 34개 키워드
📄 로딩 중: KLUE_tokenized_answers14_labeled.json
   ✅ 10개 유효 샘플, 39개 키워드
📄 로딩 중: KLUE_tokenized_answers15_labeled.json
   ✅ 10개 유효 샘플, 44개 키워드
📄 로딩 중: KLUE_tokenized_answers16_labeled.json
   ✅ 10개 유효 샘플, 55개 키워드
📄 로딩 중: KLUE_tokenized_answers17_labeled.json
   ✅ 10개 유효 샘플, 41개 키워드
📄 로딩 중: KLUE_tokenized_answers18_labeled.json
   ✅ 10개 유효 샘플, 40개 키워드
📄 로딩 중: KLUE_tokenized_answers19_labeled.json
   ✅ 10개 유효 샘플, 46개 키워드
📄 로딩 중: KLUE_tokenized_answers1_labeled.json
   ✅ 10개 유효 샘플, 48개 키워드
📄 로딩 중: KLUE_tokenized_answers20_labeled.json
   ✅ 10개 유효 샘플, 49개 키워드
📄 로딩 중: KLUE_tokenized_answers21_labeled.json
   ✅ 10개 유효 샘플, 40개 키워드
📄 로딩 중: KLUE_tokenized_answers22_labeled.json
   ✅ 10개 유효 샘플, 36개 키워드
📄 로딩 중: KLUE_tokenized_answers23_labeled.json
   ✅ 10개 유효 샘플, 56개 키워드
📄 로딩 중: KLUE_tokenized_answers24_labeled.json
   ✅ 10개 유효 샘플, 57개 키워드
📄 로딩 중: KLUE_tokenized_answers25_labeled.json
   ✅ 10개 유효 샘플, 56개 키워드
📄 로딩 중: KLUE_tokenized_answers26_labeled.json
   ✅ 10개 유효 샘플, 41개 키워드
📄 로딩 중: KLUE_tokenized_answers27_labeled.json
   ✅ 10개 유효 샘플, 51개 키워드
📄 로딩 중: KLUE_tokenized_answers28_labeled.json
   ✅ 10개 유효 샘플, 43개 키워드
📄 로딩 중: KLUE_tokenized_answers29_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers2_labeled.json
   ✅ 10개 유효 샘플, 52개 키워드
📄 로딩 중: KLUE_tokenized_answers30_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers31_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers32_labeled.json
   ✅ 11개 유효 샘플, 53개 키워드
📄 로딩 중: KLUE_tokenized_answers3_labeled.json
   ✅ 10개 유효 샘플, 47개 키워드
📄 로딩 중: KLUE_tokenized_answers4_labeled.json
   ✅ 10개 유효 샘플, 46개 키워드
📄 로딩 중: KLUE_tokenized_answers5_labeled.json
   ✅ 10개 유효 샘플, 45개 키워드
📄 로딩 중: KLUE_tokenized_answers6_labeled.json
   ✅ 10개 유효 샘플, 36개 키워드
📄 로딩 중: KLUE_tokenized_answers7_labeled.json
   ✅ 10개 유효 샘플, 38개 키워드
📄 로딩 중: KLUE_tokenized_answers8_labeled.json
   ✅ 10개 유효 샘플, 40개 키워드
📄 로딩 중: KLUE_tokenized_answers9_labeled.json
   ✅ 10개 유효 샘플, 37개 키워드

🔬 원본 데이터 320개를 1000개로 확장합니다...
✅ 데이터 확장 완료!

📊 라벨링 데이터 로드 완료:
   총 샘플: 1,000개
   총 키워드: 4,374개
   평균 키워드/샘플: 4.4개

📈 라벨 분포:
   O: 19,012개 (71.3%)
   B-KEY: 4,374개 (16.4%)
   I-KEY: 3,266개 (12.3%)

💡 라벨링 예시 (첫 번째 샘플):
C:\Users\admin\anaconda3\envs\oss-final\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(

🔧 KLUE-BERT 토크나이저 로드 완료

📊 데이터셋 분할 및 데이터 로더 생성...
✅ 데이터 분할 완료:
   훈련 데이터: 600개
   검증 데이터: 200개
   테스트 데이터: 200개
   배치 크기: 16

📈 훈련 데이터 라벨 분포:
   O: 11,541개 (71.8%)
   B-KEY: 2,615개 (16.3%)
   I-KEY: 1,908개 (11.9%)
C:\Users\admin\anaconda3\envs\oss-final\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

🏗️ KLUE-BERT 키워드 추출 모델 생성 완료 (새로 초기화됨)

🚀 KLUE-BERT 키워드 추출 모델 학습 시작!
   에포크: 6
   학습률: 2e-05
   사용 장치: cpu

📚 에포크 1/6
훈련 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [03:07<00:00,  4.95s/it, Loss=0.5505]
   훈련 손실: 0.8387
   훈련 F1: 0.6564
검증 평가: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.58s/it]
   검증 F1: 0.7851 (정밀도: 0.7981, 재현율: 0.7884)
   🏆 최고 성능 모델 저장 (F1: 0.7851) → best_model_20250618_173746.pt

📚 에포크 2/6
훈련 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [03:11<00:00,  5.04s/it, Loss=0.4670]
   훈련 손실: 0.4675
   훈련 F1: 0.8233
검증 평가: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:21<00:00,  1.64s/it]
   검증 F1: 0.8512 (정밀도: 0.8610, 재현율: 0.8513)
   🏆 최고 성능 모델 저장 (F1: 0.8512) → best_model_20250618_173746.pt

📚 에포크 3/6
훈련 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [03:12<00:00,  5.06s/it, Loss=0.2346]
   훈련 손실: 0.3253
   훈련 F1: 0.8808
검증 평가: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.59s/it]
   검증 F1: 0.8930 (정밀도: 0.9025, 재현율: 0.8904)
   🏆 최고 성능 모델 저장 (F1: 0.8930) → best_model_20250618_173746.pt

📚 에포크 4/6
훈련 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [03:07<00:00,  4.93s/it, Loss=0.2001]
   훈련 손실: 0.2324
   훈련 F1: 0.9204
검증 평가: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.58s/it]
   검증 F1: 0.9139 (정밀도: 0.9206, 재현율: 0.9121)
   🏆 최고 성능 모델 저장 (F1: 0.9139) → best_model_20250618_173746.pt

📚 에포크 5/6
훈련 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [03:07<00:00,  4.93s/it, Loss=0.2279]
   훈련 손실: 0.1777
   훈련 F1: 0.9407
검증 평가: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.58s/it]
   검증 F1: 0.9284 (정밀도: 0.9337, 재현율: 0.9270)
   🏆 최고 성능 모델 저장 (F1: 0.9284) → best_model_20250618_173746.pt

📚 에포크 6/6
훈련 6: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [03:07<00:00,  4.94s/it, Loss=0.1491]
   훈련 손실: 0.1525
   훈련 F1: 0.9490
검증 평가: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.58s/it]
   검증 F1: 0.9388 (정밀도: 0.9421, 재현율: 0.9378)
   🏆 최고 성능 모델 저장 (F1: 0.9388) → best_model_20250618_173746.pt

🎉 학습 완료! 최고 검증 F1: 0.9388

📥 최고 성능 모델 로드: best_model_20250618_173746.pt
테스트 평가: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:20<00:00,  1.60s/it]

🔍 최종 테스트 평가 결과:
   정밀도: 0.9303
   재현율: 0.9253
   F1 스코어: 0.9266

📊 상세 분류 리포트:
              precision    recall  f1-score   support

           O       0.97      0.93      0.95      3906
       B-KEY       0.83      0.95      0.88       884
       I-KEY       0.82      0.88      0.85       699

    accuracy                           0.93      5489
   macro avg       0.87      0.92      0.89      5489
weighted avg       0.93      0.93      0.93      5489


💾 모델 저장 중: klue_keyword_extractor_20250618_173746
✅ 모델 저장 완료!
   모델 경로: klue_keyword_extractor_20250618_173746/
   설정 파일: klue_keyword_extractor_20250618_173746/training_config.json

🧪 추론 테스트 (최대 6개 키워드)
==================================================

테스트 1: 대학에서 처음으로 컴퓨터를 사용해 보았던 기억이 있어요. 신기하고 어색했어요.
키워드 추출 결과:
  🔑 대학 -> B-KEY
  🔑 컴퓨터 -> B-KEY
  🔑 사용 -> B-KEY
  ↳ ##해 -> I-KEY
  ↳ 보 -> I-KEY
  ↳ ##았 -> I-KEY
  ↳ ##던 -> I-KEY
🎯 추출된 키워드: ['대학', '컴퓨터', '사용해보았던']

테스트 2: 자식들이 대학에 합격한 순간을 잊지 못해요. 서로를 끌어안고 펑펑 울었던 것 같아요.
키워드 추출 결과:
  🔑 자식 -> B-KEY
  ↳ ##들이 -> I-KEY
  🔑 대학 -> B-KEY
  🔑 합격 -> B-KEY
  ↳ ##한 -> I-KEY
  🔑 끌어안 -> B-KEY
  ↳ ##고 -> I-KEY
  🔑 울 -> B-KEY
  ↳ ##었 -> I-KEY
  ↳ ##던 -> I-KEY
🎯 추출된 키워드: ['자식들이', '대학', '합격한', '끌어안고', '울었던']

테스트 3: 남편이 연락을 받으면 꼭 청혼해야 겠다는 마음으로 연락했어요. 다행이 청혼에 성공하고 결혼까지 했네요.
키워드 추출 결과:
  🔑 남편 -> B-KEY
  🔑 연락 -> B-KEY
  🔑 청혼 -> B-KEY
  ↳ ##해야 -> I-KEY
  🔑 연락 -> B-KEY
  🔑 청혼 -> B-KEY
  🔑 결혼 -> B-KEY
🎯 추출된 키워드: ['남편', '연락', '청혼해야', '연락', '청혼', '결혼']

테스트 4: 삶이 힘들어도 다시 일어설 용기가 필요하다는걸 아이들에게 항상 강조해줬던 것 같아요.
키워드 추출 결과:
  🔑 삶 -> B-KEY
  🔑 다시 -> B-KEY
  🔑 일어 -> B-KEY
  ↳ ##설 -> I-KEY
  ↳ 용기 -> I-KEY
  🔑 필요 -> B-KEY
  ↳ ##하 -> I-KEY
  ↳ ##다는 -> I-KEY
  🔑 아이 -> B-KEY
  ↳ ##들 -> I-KEY
🎯 추출된 키워드: ['삶', '다시', '일어설용기', '필요하다는', '아이들']
