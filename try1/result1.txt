🎯 개선된 4단계: KLUE-BERT 키워드 추출 모델 학습
============================================================
라벨링된 데이터를 사용하여 단순 키워드 추출 모델 학습
라벨 체계: O (비키워드), B-KEY (키워드 시작), I-KEY (키워드 내부)
============================================================
🧹 이전 학습 결과 정리 중...
   🗑️ 파일 삭제: best_model.pt
   🗑️ 파일 삭제: training_history1.png
✅ 2개 파일/폴더 정리 완료

🕐 학습 세션 ID: 20250618_160424
📂 라벨링된 KLUE 데이터 로드 중...
✅ 발견된 라벨링 파일: 32개
📄 로딩 중: KLUE_tokenized_answers10_labeled.json
   ⚠️ 유효하지 않은 라벨 포함된 샘플 건너뜀
   ✅ 9개 유효 샘플, 34개 키워드
📄 로딩 중: KLUE_tokenized_answers11_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers12_labeled.json
   ✅ 10개 유효 샘플, 36개 키워드
📄 로딩 중: KLUE_tokenized_answers13_labeled.json
   ✅ 10개 유효 샘플, 34개 키워드
📄 로딩 중: KLUE_tokenized_answers14_labeled.json
   ✅ 10개 유효 샘플, 39개 키워드
📄 로딩 중: KLUE_tokenized_answers15_labeled.json
   ✅ 10개 유효 샘플, 44개 키워드
📄 로딩 중: KLUE_tokenized_answers16_labeled.json
   ✅ 10개 유효 샘플, 55개 키워드
📄 로딩 중: KLUE_tokenized_answers17_labeled.json
   ✅ 10개 유효 샘플, 41개 키워드
📄 로딩 중: KLUE_tokenized_answers18_labeled.json
   ✅ 10개 유효 샘플, 40개 키워드
📄 로딩 중: KLUE_tokenized_answers19_labeled.json
   ✅ 10개 유효 샘플, 46개 키워드
📄 로딩 중: KLUE_tokenized_answers1_labeled.json
   ⚠️ 토큰-라벨 길이 불일치 샘플 건너뜀
   ✅ 9개 유효 샘플, 34개 키워드
📄 로딩 중: KLUE_tokenized_answers20_labeled.json
   ✅ 10개 유효 샘플, 49개 키워드
📄 로딩 중: KLUE_tokenized_answers21_labeled.json
   ✅ 10개 유효 샘플, 40개 키워드
📄 로딩 중: KLUE_tokenized_answers22_labeled.json
   ✅ 10개 유효 샘플, 36개 키워드
📄 로딩 중: KLUE_tokenized_answers23_labeled.json
   ✅ 10개 유효 샘플, 56개 키워드
📄 로딩 중: KLUE_tokenized_answers24_labeled.json
   ✅ 10개 유효 샘플, 57개 키워드
📄 로딩 중: KLUE_tokenized_answers25_labeled.json
   ✅ 10개 유효 샘플, 56개 키워드
📄 로딩 중: KLUE_tokenized_answers26_labeled.json
   ✅ 10개 유효 샘플, 41개 키워드
📄 로딩 중: KLUE_tokenized_answers27_labeled.json
   ✅ 10개 유효 샘플, 51개 키워드
📄 로딩 중: KLUE_tokenized_answers28_labeled.json
   ✅ 10개 유효 샘플, 43개 키워드
📄 로딩 중: KLUE_tokenized_answers29_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers2_labeled.json
   ✅ 10개 유효 샘플, 52개 키워드
📄 로딩 중: KLUE_tokenized_answers30_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers31_labeled.json
   ✅ 10개 유효 샘플, 42개 키워드
📄 로딩 중: KLUE_tokenized_answers32_labeled.json
   ✅ 11개 유효 샘플, 53개 키워드
📄 로딩 중: KLUE_tokenized_answers3_labeled.json
   ✅ 10개 유효 샘플, 47개 키워드
📄 로딩 중: KLUE_tokenized_answers4_labeled.json
   ✅ 10개 유효 샘플, 46개 키워드
📄 로딩 중: KLUE_tokenized_answers5_labeled.json
   ✅ 10개 유효 샘플, 45개 키워드
📄 로딩 중: KLUE_tokenized_answers6_labeled.json
   ✅ 10개 유효 샘플, 36개 키워드
📄 로딩 중: KLUE_tokenized_answers7_labeled.json
   ✅ 10개 유효 샘플, 38개 키워드
📄 로딩 중: KLUE_tokenized_answers8_labeled.json
   ✅ 10개 유효 샘플, 40개 키워드
📄 로딩 중: KLUE_tokenized_answers9_labeled.json
   ✅ 10개 유효 샘플, 37개 키워드

📊 라벨링 데이터 로드 완료:
   총 샘플: 319개
   총 키워드: 1,394개
   평균 키워드/샘플: 4.4개

📈 라벨 분포:
   O: 6,050개 (71.5%)
   B-KEY: 1,394개 (16.5%)
   I-KEY: 1,017개 (12.0%)

💡 라벨링 예시:
   원본: 아이들이 아파서 급하게 응급실에 갔을 때 진료 순서를 바꿔준 학생이 있었어요. 그때는 정신...
   🔑 아이 -> B-KEY
   🔑 응급실 -> B-KEY
C:\Users\admin\anaconda3\envs\oss-final\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
tokenizer_config.json: 100%|███████████████████████████████████████████████████████████| 289/289 [00:00<00:00, 134kB/s]
C:\Users\admin\anaconda3\envs\oss-final\lib\site-packages\huggingface_hub\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\Users\admin\.cache\huggingface\hub\models--klue--bert-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.
To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development
  warnings.warn(message)
config.json: 100%|████████████████████████████████████████████████████████████████████████████| 425/425 [00:00<?, ?B/s]
vocab.txt: 100%|████████████████████████████████████████████████████████████████████| 248k/248k [00:00<00:00, 14.7MB/s]
tokenizer.json: 100%|███████████████████████████████████████████████████████████████| 495k/495k [00:00<00:00, 10.4MB/s]
special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:00<?, ?B/s]

🔧 KLUE-BERT 토크나이저 로드 완료

📊 데이터셋 분할 및 데이터 로더 생성...
✅ 데이터 분할 완료:
   훈련 데이터: 191개
   검증 데이터: 64개
   테스트 데이터: 64개
   배치 크기: 16

📈 훈련 데이터 라벨 분포:
   O: 3,618개 (72.1%)
   B-KEY: 825개 (16.4%)
   I-KEY: 574개 (11.4%)
C:\Users\admin\anaconda3\envs\oss-final\lib\site-packages\huggingface_hub\file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`
model.safetensors: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 445M/445M [00:46<00:00, 9.50MB/s]
Some weights of the model checkpoint at klue/bert-base were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

🏗️ KLUE-BERT 키워드 추출 모델 생성 완료 (새로 초기화됨)

🚀 KLUE-BERT 키워드 추출 모델 학습 시작!
   에포크: 5
   학습률: 2e-05
   사용 장치: cpu

📚 에포크 1/5
훈련 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:00<00:00,  5.03s/it, Loss=0.9170]
   훈련 손실: 1.0056
   훈련 F1: 0.5916
검증 평가: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.64s/it]
   검증 F1: 0.6787 (정밀도: 0.6512, 재현율: 0.7170)
   🏆 최고 성능 모델 저장 (F1: 0.6787) → best_model_20250618_160424.pt

📚 에포크 2/5
훈련 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:00<00:00,  5.05s/it, Loss=0.6839]
   훈련 손실: 0.6960
   훈련 F1: 0.7331
검증 평가: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.63s/it]
   검증 F1: 0.7308 (정밀도: 0.7298, 재현율: 0.7446)
   🏆 최고 성능 모델 저장 (F1: 0.7308) → best_model_20250618_160424.pt

📚 에포크 3/5
훈련 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:00<00:00,  5.02s/it, Loss=0.5504]
   훈련 손실: 0.5737
   훈련 F1: 0.7799
검증 평가: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.68s/it]
   검증 F1: 0.7408 (정밀도: 0.7495, 재현율: 0.7481)
   🏆 최고 성능 모델 저장 (F1: 0.7408) → best_model_20250618_160424.pt

📚 에포크 4/5
훈련 4: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:00<00:00,  5.02s/it, Loss=0.5343]
   훈련 손실: 0.5069
   훈련 F1: 0.8089
검증 평가: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.68s/it]
   검증 F1: 0.7572 (정밀도: 0.7631, 재현율: 0.7622)
   🏆 최고 성능 모델 저장 (F1: 0.7572) → best_model_20250618_160424.pt

📚 에포크 5/5
훈련 5: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12/12 [01:00<00:00,  5.04s/it, Loss=0.4337]
   훈련 손실: 0.4812
   훈련 F1: 0.8178
검증 평가: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.66s/it]
   검증 F1: 0.7608 (정밀도: 0.7685, 재현율: 0.7633)
   🏆 최고 성능 모델 저장 (F1: 0.7608) → best_model_20250618_160424.pt

🎉 학습 완료! 최고 검증 F1: 0.7608

📥 최고 성능 모델 로드: best_model_20250618_160424.pt
테스트 평가: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.68s/it]

🔍 최종 테스트 평가 결과:
   정밀도: 0.7885
   재현율: 0.7812
   F1 스코어: 0.7756

📊 상세 분류 리포트:
              precision    recall  f1-score   support

           O       0.87      0.85      0.86      1240
       B-KEY       0.57      0.85      0.68       268
       I-KEY       0.61      0.34      0.44       229

    accuracy                           0.78      1737
   macro avg       0.68      0.68      0.66      1737
weighted avg       0.79      0.78      0.78      1737


💾 모델 저장 중: klue_keyword_extractor_20250618_160424
✅ 모델 저장 완료!
   모델 경로: klue_keyword_extractor_20250618_160424/
   설정 파일: klue_keyword_extractor_20250618_160424/training_config.json

🧪 추론 테스트 (최대 6개 키워드)
==================================================

테스트 1: 대학에서 처음으로 컴퓨터를 사용해 보았던 기억이 있어요. 신기하고 어색했어요.
키워드 추출 결과:
  🔑 대학 -> B-KEY
  🔑 컴퓨터 -> B-KEY
  🔑 사용 -> B-KEY
  ↳ ##해 -> I-KEY
  ↳ 보 -> I-KEY
  ↳ ##았 -> I-KEY
  🔑 어색 -> B-KEY
🎯 추출된 키워드: ['대학', '컴퓨터', '사용해보았', '어색']

테스트 2: 자식들이 대학에 합격한 순간을 잊지 못해요. 서로를 끌어안고 펑펑 울었던 것 같아요.
키워드 추출 결과:
  🔑 자식 -> B-KEY
  ↳ ##들이 -> I-KEY
  🔑 대학 -> B-KEY
  🔑 합격 -> B-KEY
  ↳ ##한 -> I-KEY
  🔑 서로 -> B-KEY
  🔑 끌어안 -> B-KEY
  🔑 펑펑 -> B-KEY
🎯 추출된 키워드: ['자식들이', '대학', '합격한', '서로', '끌어안', '펑펑']

테스트 3: 남편이 연락을 받으면 꼭 청혼해야 겠다는 마음으로 연락했어요. 다행이 청혼에 성공하고 결혼까지 했네요.
키워드 추출 결과:
  🔑 남편 -> B-KEY
  🔑 연락 -> B-KEY
  🔑 청혼 -> B-KEY
  🔑 연락 -> B-KEY
  🔑 청혼 -> B-KEY
  🔑 결혼 -> B-KEY
🎯 추출된 키워드: ['남편', '연락', '청혼', '연락', '청혼', '결혼']

테스트 4: 삶이 힘들어도 다시 일어설 용기가 필요하다는걸 아이들에게 항상 강조해줬던 것 같아요.
키워드 추출 결과:
  🔑 삶 -> B-KEY
  🔑 힘들 -> B-KEY
  🔑 일어 -> B-KEY
  ↳ ##설 -> I-KEY
  🔑 용기 -> B-KEY
  🔑 아이 -> B-KEY
  ↳ ##들 -> I-KEY
  🔑 강조 -> B-KEY
🎯 추출된 키워드: ['삶', '힘들', '일어설', '용기', '아이들', '강조']
